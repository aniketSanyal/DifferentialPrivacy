{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketSanyal/DifferentialPrivacy/blob/main/PromptDPSGD_softPrompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UshIzJ9_PzH3"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets opacus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMH8yiluP1Do"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaOyoe-_RDsw"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"prajjwal1/bert-tiny\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyNzoBUpUYHk"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  num_train_epochs = 3\n",
        "  learning_rate = 5e-4\n",
        "  n_prompt_tokens = 10\n",
        "  random_range  = 0.5\n",
        "  batch_size = 64\n",
        "  max_grad_norm = 0.1\n",
        "args = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34nBdLVU8hTZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "tokenized_dataset = raw_datasets.map(\n",
        "    lambda example: tokenizer(example[\"sentence\"], max_length=64, padding='max_length', truncation=True),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(['idx'])\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jVLJPQw4Ky1"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def custom_collate(batch):\n",
        "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True, padding_value=0)\n",
        "    labels = torch.stack([item['labels'] for item in batch])\n",
        "\n",
        "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-DynuZN4PNL"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(tokenized_dataset[\"train\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)\n",
        "test_dataloader = DataLoader(tokenized_dataset[\"validation\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77YWgWqGTyfT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC7hDM6aUIEg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHeEihcOT3Xg"
      },
      "outputs": [],
      "source": [
        "class PROMPTEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                wte: nn.Embedding,\n",
        "                n_tokens: int = 10,\n",
        "                random_range: float = 0.5,\n",
        "                initialize_from_vocab: bool = True):\n",
        "        super(PROMPTEmbedding, self).__init__()\n",
        "        self.wte = wte\n",
        "        self.n_tokens = n_tokens\n",
        "        self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(wte,\n",
        "                                                                               n_tokens,\n",
        "                                                                               random_range,\n",
        "                                                                               initialize_from_vocab))\n",
        "\n",
        "    def initialize_embedding(self,\n",
        "                             wte: nn.Embedding,\n",
        "                             n_tokens: int = 10,\n",
        "                             random_range: float = 0.5,\n",
        "                             initialize_from_vocab: bool = True):\n",
        "        if initialize_from_vocab:\n",
        "            return self.wte.weight[:n_tokens].clone().detach()\n",
        "        return torch.FloatTensor(wte.weight.size(1), n_tokens).uniform_(-random_range, random_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        input_embedding = self.wte(tokens[:, self.n_tokens:])\n",
        "        learned_embedding = self.learned_embedding.repeat(input_embedding.size(0), 1, 1)\n",
        "        return torch.cat([learned_embedding, input_embedding], 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_new_soft_prompt_model(num_labels):\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)\n",
        "  prompt_embedding = PROMPTEmbedding(model.get_input_embeddings(),\n",
        "                      n_tokens=args.n_prompt_tokens,\n",
        "                      initialize_from_vocab=True)\n",
        "  model.set_input_embeddings(prompt_embedding)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "VdFA5Wqfdz8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp-QvquIjZvA"
      },
      "outputs": [],
      "source": [
        "total_params = 0\n",
        "for p in prompt_embedding.learned_embedding:\n",
        "    total_params += p.numel()\n",
        "print(total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y7oTb35UbJg"
      },
      "outputs": [],
      "source": [
        "total_params = 0\n",
        "for p in model.parameters():\n",
        "    total_params += p.numel()\n",
        "print(total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0zhTls_k2gu"
      },
      "outputs": [],
      "source": [
        "def get_soft_prompt_optimiser(model):\n",
        "  optimiser_grouped_parameters = [\n",
        "      {\n",
        "        \"params\": [p for n, p in model.named_parameters() if n == \"bert.embeddings.word_embeddings.learned_embedding\"],\n",
        "      }\n",
        "    ]\n",
        "\n",
        "# Exclude other parameters from optimization\n",
        "  for n, p in model.named_parameters():\n",
        "      if not n == \"bert.embeddings.word_embeddings.learned_embedding\":\n",
        "        p.requires_grad = False\n",
        "      else:\n",
        "       p.requires_grad =True\n",
        "\n",
        "  optimiser = optim.SGD(optimiser_grouped_parameters, lr=args.learning_rate)\n",
        "  return optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2y7NZ7XuK5Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "# define evaluation cycle\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "\n",
        "    loss_arr = []\n",
        "    accuracy_arr = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        #batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        loss, logits = outputs[:2]\n",
        "\n",
        "        preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "        labels =batch['labels'].detach().cpu().numpy()\n",
        "\n",
        "        loss_arr.append(loss.item())\n",
        "        accuracy_arr.append(accuracy(preds, labels))\n",
        "\n",
        "    model.train()\n",
        "    return np.mean(loss_arr), np.mean(accuracy_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u47uGbF4nEUS"
      },
      "outputs": [],
      "source": [
        "DELTA = 1 / len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJWTSkWznet7"
      },
      "outputs": [],
      "source": [
        "model = get_new_soft_prompt_model(2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model = model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbYVdOAhuwVx"
      },
      "outputs": [],
      "source": [
        "LOGGING_INTERVAL = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF5thNGnue0J"
      },
      "outputs": [],
      "source": [
        "def train_soft_prompt(model,optimiser, train_dataloader):\n",
        "  for epoch in range(1, args.num_train_epochs+1):\n",
        "    losses = []\n",
        "\n",
        "    for  step, batch in enumerate(train_dataloader):\n",
        "            optimiser.zero_grad()\n",
        "            #batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch) # output = loss, logits, hidden_states, attentions\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "            loss.backward()\n",
        "            losses.append(loss.item())\n",
        "            optimiser.step()\n",
        "\n",
        "            if step > 0 and step % LOGGING_INTERVAL == 0:\n",
        "                train_loss = np.mean(losses)\n",
        "\n",
        "                eval_loss, eval_accuracy = evaluate(model)\n",
        "\n",
        "                print(\n",
        "                  f\"Epoch: {epoch} | \"\n",
        "                  f\"Step: {step} | \"\n",
        "                  f\"Train loss: {train_loss:.3f} | \"\n",
        "                  f\"Eval loss: {eval_loss:.3f} | \"\n",
        "                  f\"Eval accuracy: {eval_accuracy:.3f} | \"\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_soft_prompt_DP(model,optimiser, train_dataloader):\n",
        "  for epoch in range(1, args.num_train_epochs+1):\n",
        "    losses = []\n",
        "\n",
        "    for  step, batch in enumerate(train_dataloader):\n",
        "            optimiser.zero_grad()\n",
        "            #batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch) # output = loss, logits, hidden_states, attentions\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "            loss.backward()\n",
        "            losses.append(loss.item())\n",
        "            optimiser.step()\n",
        "\n",
        "            if step > 0 and step % LOGGING_INTERVAL == 0:\n",
        "                train_loss = np.mean(losses)\n",
        "                eps = privacy_engine.get_epsilon(DELTA)\n",
        "                eval_loss, eval_accuracy = evaluate(model)\n",
        "\n",
        "                print(\n",
        "                  f\"Epoch: {epoch} | \"\n",
        "                  f\"Step: {step} | \"\n",
        "                  f\"Train loss: {train_loss:.3f} | \"\n",
        "                  f\"Eval loss: {eval_loss:.3f} | \"\n",
        "                  f\"Eval accuracy: {eval_accuracy:.3f} | \"\n",
        "                  f\"ɛ: {eps:.2f}\"\n",
        "                )"
      ],
      "metadata": {
        "id": "My7KLqqAdOEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =get_new_soft_prompt_model(2)\n",
        "optimiser = get_soft_prompt_optimiser(model)"
      ],
      "metadata": {
        "id": "jBkfKAq7gkXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_soft_prompt(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "OewMWd_ddZqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXy458oJuRmu"
      },
      "outputs": [],
      "source": [
        "from opacus import PrivacyEngine\n",
        "\n",
        "privacy_engine = PrivacyEngine()\n",
        "model = get_new_soft_prompt_model(2)\n",
        "optimiser = get_soft_prompt_optimiser(model)\n",
        "model.train()\n",
        "model, optimiser, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimiser,\n",
        "    data_loader=train_dataloader,\n",
        "    target_delta=DELTA,\n",
        "    target_epsilon=8,\n",
        "    epochs=args.num_train_epochs,\n",
        "    max_grad_norm=args.max_grad_norm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =get_new_soft_prompt_model(2)\n",
        "optimiser = get_soft_prompt_optimiser(model)"
      ],
      "metadata": {
        "id": "uTMkG-wwgmrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_soft_prompt_DP(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "EPl0TOY5ek0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR QNLI dataset"
      ],
      "metadata": {
        "id": "skP-GQBnzYfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "As03aRB3zZ25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"glue\", \"qnli\")"
      ],
      "metadata": {
        "id": "gOUOkbBAuxkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train'] = raw_datasets['train'].select([i for i in range(50000)])\n",
        "\n",
        "raw_datasets['validation'] = raw_datasets['validation'].select([i for i in range(5000)])\n",
        "\n",
        "raw_datasets['test'] = raw_datasets['test'].select([i for i in range(5000)])"
      ],
      "metadata": {
        "id": "XESkK5SxYssq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "tokenized_dataset = raw_datasets.map(\n",
        "    lambda example: tokenizer(example[\"question\"],example[\"sentence\"] ,max_length=64, padding='max_length', truncation=True),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(['idx', 'sentence', 'question'])\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "4AaUiHry0AKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(tokenized_dataset[\"train\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)\n",
        "test_dataloader = DataLoader(tokenized_dataset[\"validation\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)"
      ],
      "metadata": {
        "id": "Kk9UJEwV0WyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_new_soft_prompt_model(2)\n",
        "optimiser = get_soft_prompt_optimiser(model)"
      ],
      "metadata": {
        "id": "adRDXA3KfAFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_soft_prompt(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "HijjzBNifHhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =get_new_soft_prompt_model(2)\n",
        "optimiser = get_soft_prompt_optimiser(model)\n"
      ],
      "metadata": {
        "id": "fdNAKAwZfMYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from opacus import PrivacyEngine\n",
        "model.train()\n",
        "privacy_engine = PrivacyEngine()\n",
        "\n",
        "model, optimiser, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimiser,\n",
        "    data_loader=train_dataloader,\n",
        "    target_delta=DELTA,\n",
        "    target_epsilon=8,\n",
        "    epochs=args.num_train_epochs,\n",
        "    max_grad_norm=args.max_grad_norm,\n",
        ")"
      ],
      "metadata": {
        "id": "nnh1M8cJZYMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_soft_prompt_DP(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "kakq4LlIffrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR QQP"
      ],
      "metadata": {
        "id": "dguV61LiNvPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"glue\", \"qqp\")"
      ],
      "metadata": {
        "id": "KJfvrEdYNwQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "9F5WgGi3N7GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train'] = raw_datasets['train'].select([i for i in range(50000)])\n",
        "raw_datasets['validation'] = raw_datasets['validation'].select([i for i in range(5000)])\n",
        "raw_datasets['test'] = raw_datasets['test'].select([i for i in range(5000)])"
      ],
      "metadata": {
        "id": "HqLIMF3lPmPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "tokenized_dataset = raw_datasets.map(\n",
        "    lambda example: tokenizer(example[\"question1\"],example[\"question2\"] ,max_length=64, padding='max_length', truncation=True),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(['idx', 'question1', 'question2'])\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "1J7LS6ZOO5jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(tokenized_dataset[\"train\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)\n",
        "test_dataloader = DataLoader(tokenized_dataset[\"validation\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)"
      ],
      "metadata": {
        "id": "TubjjG1WPRwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =get_new_soft_prompt_model(2)\n",
        "optimiser = get_soft_prompt_optimiser(model)"
      ],
      "metadata": {
        "id": "1ecS38epf4Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_soft_prompt(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "u2Fz2E0Of838"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =get_new_soft_prompt_model(2)\n",
        "optimiser = get_soft_prompt_optimiser(model)"
      ],
      "metadata": {
        "id": "AmO-N6p8gFmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "privacy_engine = PrivacyEngine()\n",
        "model.train()\n",
        "model, optimiser, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimiser,\n",
        "    data_loader=train_dataloader,\n",
        "    target_delta=DELTA,\n",
        "    target_epsilon=8,\n",
        "    epochs=args.num_train_epochs,\n",
        "    max_grad_norm=args.max_grad_norm,\n",
        ")"
      ],
      "metadata": {
        "id": "DWunIi8EaS19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_soft_prompt_DP(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "V-m5FPqXgJiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For MNLI"
      ],
      "metadata": {
        "id": "VN9-fL9QGc7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"glue\", \"mnli\")"
      ],
      "metadata": {
        "id": "djnLKpInyum0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"glue\", \"mnli\")"
      ],
      "metadata": {
        "id": "Z6-lT-OwOo0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_datasets['train'] = raw_datasets['train'].select([i for i in range(50000)])\n",
        "\n",
        "raw_datasets['validation_matched'] = raw_datasets['validation_matched'].select([i for i in range(5000)])\n",
        "\n"
      ],
      "metadata": {
        "id": "rCnw8qNsGfMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint, num_labels =3)"
      ],
      "metadata": {
        "id": "fLCaJnflG4xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "tokenized_dataset = raw_datasets.map(\n",
        "    lambda example: tokenizer(example[\"premise\"],example[\"hypothesis\"] ,max_length=64, padding='max_length', truncation=True),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(['idx', 'premise', 'hypothesis'])\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "uJ-UIkWNG4xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(tokenized_dataset[\"train\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)\n",
        "test_dataloader = DataLoader(tokenized_dataset[\"validation_matched\"], shuffle=False, batch_size=args.batch_size, collate_fn=custom_collate)"
      ],
      "metadata": {
        "id": "NR1At2D2G4xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =get_new_soft_prompt_model(3)\n",
        "optimiser = get_soft_prompt_optimiser(model)"
      ],
      "metadata": {
        "id": "7tE3G9W_gXAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "train_soft_prompt(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "a7rKo8rLG4xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =get_new_soft_prompt_model(3)\n",
        "optimiser = get_soft_prompt_optimiser(model)"
      ],
      "metadata": {
        "id": "ZF000gwjgz_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from opacus import PrivacyEngine\n",
        "model.train()\n",
        "privacy_engine = PrivacyEngine()\n",
        "\n",
        "model, optimiser, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimiser,\n",
        "    data_loader=train_dataloader,\n",
        "    target_delta=DELTA,\n",
        "    target_epsilon=8,\n",
        "    epochs=args.num_train_epochs,\n",
        "    max_grad_norm=args.max_grad_norm,\n",
        ")"
      ],
      "metadata": {
        "id": "FpP0EqyDTpRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_soft_prompt_DP(model, optimiser, train_dataloader)"
      ],
      "metadata": {
        "id": "ae0vNwthTput"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLGRAwg+Y0PFPl6UQDsTLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}